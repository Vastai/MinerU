## 0. ç€šåšåŠå¯¼ä½“

![vastaitech](https://github.com/Vastai/VastModelZOO/blob/main/images/index/logo.png?raw=true)

- å®˜æ–¹ç½‘å€ï¼šhttps://www.vastaitech.com
- æ¨¡å‹ä¸­å¿ƒï¼šhttps://github.com/Vastai/VastModelZOO

## 1. å®˜æ–¹æ”¯æŒ

- âœ¨ä¾èµ–MinerUå®˜æ–¹ä»“åº“ï¼Œé›¶ä»£ç ä¿®æ”¹ï¼Œå¯å®ç°`MinerU2.5-2509-1.2B`æ¨¡å‹åœ¨VACCç¡¬ä»¶ä¸‹æ¨ç†
- https://opendatalab.github.io/MinerU/zh/usage/acceleration_cards/VastAI
- https://github.com/opendatalab/MinerU/blob/master/docs/zh/usage/acceleration_cards/VastAI.md

## 2. æµ‹è¯•å¹³å°

- ä»¥ä¸‹ä¸ºæœ¬æŒ‡å—æµ‹è¯•ä½¿ç”¨çš„å¹³å°ä¿¡æ¯ï¼Œä¾›å‚è€ƒ
    ```
    os: Ubuntu-22.04.3-LTS-x86_64
    cpu: Hygon C86-4G
    gpu: VA16 / VA1L / VA10L
    torch: 2.8.0+cpu
    torch-vacc: 1.3.4.1081
    vllm: 0.11.1.dev0+gb8b302cde.d20251030.cpu
    vllm-vacc: 0.11.0.1081
    driver: 00.26.01.12 d3_3_v2_9_a3_1 eda8215 20260112
    docker: 28.1.1
    ```

## 3. ç¯å¢ƒå‡†å¤‡

> [!TIP]
> - æ­¥éª¤`3.1/3.2/3.3`ï¼Œå¯ä»»é€‰å…¶ä¸€ä½¿ç”¨

### 3.1 ä»åŸºç¡€é•œåƒå®‰è£…

- è·å–vllm_vaccåŸºç¡€é•œåƒ
    ```bash
    sudo docker pull harbor.vastaitech.com/ai_deliver/vllm_vacc:AID-Sample-005
    ```

- å¯åŠ¨å®¹å™¨
    ```bash
    sudo docker run -it \
        --privileged=true \
        --shm-size=256g \
        --name vllm_service \
        --ipc=host \
        --network=host \
        harbor.vastaitech.com/ai_deliver/vllm_vacc:AID-Sample-005 bash
    ```

- å®‰è£…MinerU

   - å‚è€ƒå®˜æ–¹æ–‡æ¡£å®‰è£…ï¼š[README_zh-CN.md#å®‰è£…-mineru](https://github.com/opendatalab/MinerU/blob/master/README_zh-CN.md#å®‰è£…-mineru)

        ```bash
        # å¯åŠ¨å®¹å™¨
        # sudo docker exec -it vllm_service bash
        
        # å¯é€‰pypiæº
        # https://mirrors.163.com/pypi/simple/
        # https://mirrors.aliyun.com/pypi/simple/
        # https://pypi.mirrors.ustc.edu.cn/simple/
        # https://pypi.tuna.tsinghua.edu.cn/simple/
        # https://mirror.baidu.com/pypi/simple

        # é€šè¿‡æºç å®‰è£…MinerU
        git clone https://github.com/opendatalab/MinerU.git
        git checkout 1c57a7bd9bfcb8803bca3b0854f9e331b335a142
        pip install -e .[core] -i https://mirrors.aliyun.com/pypi/simple

        # æˆ–ä½¿ç”¨pipå®‰è£…MinerU
        pip install -U "mineru[core]==2.7.3" -i https://mirrors.aliyun.com/pypi/simple
        ```

### 3.2 ç¼–è¯‘å®Œæ•´é•œåƒ

- ç¼–è¯‘é•œåƒ

  > - [vacc.Dockerfile](./vacc.Dockerfile)
  
  ```bash
  sudo docker build -t vaparser:v0.4.0 -f vacc.Dockerfile .
  ```

- å¯åŠ¨å®¹å™¨
    ```bash
    sudo docker run -it \
        --privileged=true \
        --shm-size=256g \
        --name vllm_service \
        --ipc=host \
        --network=host \
        vaparser:v0.4.0 bash
    ```


### 3.3 æ‹‰å–å®Œæ•´é•œåƒ

- è·å–å®Œæ•´é•œåƒ

  ```bash
  sudo docker pull harbor.vastaitech.com/ai_deliver/vaparser:v0.4.0
  ```

- å¯åŠ¨å®¹å™¨
  ```bash
  sudo docker run -it \
      --privileged=true \
      --shm-size=256g \
      --name vllm_service \
      --ipc=host \
      --network=host \
      harbor.vastaitech.com/ai_deliver/vaparser:v0.4.0 bash
  ```

> [!NOTE]
> - `vllm_vacc`åŸºç¡€é•œåƒå†…å·²åŒ…å«`torch/vllm`ç­‰ç›¸å…³ä¾èµ–
> - æˆªè‡³`2026/01/28`ï¼Œ`VastAI`å·²æ”¯æŒ`MinerU`è‡³æœ€æ–°ç‰ˆæœ¬`2.7.3`ï¼Œ`masteråˆ†æ”¯1c57a7bd`
> - å’Œ`NVIDIA`ç¡¬ä»¶ä¸‹`CUDA_VISIBLE_DEVICES`ç±»ä¼¼ï¼›åœ¨`VastAI`ç¡¬ä»¶ä¸­å¯ä»¥ä½¿ç”¨`VACC_VISIBLE_DEVICES`æŒ‡å®š`å¯è§è®¡ç®—å¡ID`ï¼Œå¦‚`-e VACC_VISIBLE_DEVICES=0,1,2,3`
> - éœ€æŒ‡å®šé€‚å½“çš„`--shm-size`è™šæ‹Ÿå†…å­˜

## 4. MinerUåŠŸèƒ½

> [!NOTE]
> - `VastAI`åŠ é€Ÿå¡å½“å‰ä»…æ”¯æŒ`*-auto-engine`å’Œ`*-http-client`å½¢å¼è¿›è¡Œ`VLM`æ¨¡å‹æ¨ç†ï¼Œå‚è€ƒï¼š[README_zh-CN.md#æœ¬åœ°éƒ¨ç½²](https://github.com/opendatalab/MinerU/blob/master/README_zh-CN.md#æœ¬åœ°éƒ¨ç½²)

- è¿›å…¥å®¹å™¨
    ```bash
    sudo docker exec -it vllm_service bash
    ```

- ä½¿ç”¨MinerU

    - æ¨¡å‹å‡†å¤‡ï¼Œå‚è€ƒå®˜æ–¹ä»‹ç»ï¼š[model_source.md](https://github.com/opendatalab/MinerU/blob/master/docs/zh/usage/model_source.md)

    - æ–¹å¼ä¸€ï¼š`vlm-auto-engine`/`hybrid-auto-engine`

        ```bash
        export MINERU_MODEL_SOURCE=modelscope

        # step1, ä»¥`vlm-auto-engine`æ–¹å¼å¯åŠ¨MinerUè§£æä»»åŠ¡
        mineru -p demo/pdfs/demo1.pdf \
        -o ./output \
        -b vlm-auto-engine \
        --http-timeout 1200 \
        --tensor-parallel-size 2 \
        --enforce_eager \
        --trust-remote-code \
        --max-model-len 16384
        ```

    - æ–¹å¼äºŒï¼š`vlm-http-client`/`hybrid-http-client`

        ```bash
        # step1, å¯åŠ¨vLLM API server
        ## å·²é€šè¿‡modelscopeä¸‹è½½æ¨¡å‹è‡³é»˜è®¤ç›®å½•
        vllm serve /root/.cache/modelscope/hub/models/OpenDataLab/MinerU2.5-2509-1.2B \
        --tensor-parallel-size 2 \
        --trust-remote-code \
        --enforce_eager \
        --port 8090 \
        --max-model-len 16384 \
        --served-model-name MinerU2.5-2509-1.2B

        # step2ï¼Œä»¥`vlm-http-client`æ–¹å¼å¯åŠ¨MinerUè§£æä»»åŠ¡
        mineru -p demo/pdfs/demo1.pdf \
        -o ./output \
        -b vlm-http-client \
        -u http://127.0.0.1:8090 \
        --http-timeout 1200
        ```


> [!NOTE]
> - æ³¨æ„åœ¨æ‰§è¡Œä»»æ„ä¸`vllm`ç›¸å…³å‘½ä»¤éœ€è¿½åŠ `--enforce_eager`å‚æ•°
> - å…¶å®ƒä½¿ç”¨æ–¹æ³•ï¼Œå‚è€ƒå®˜æ–¹ä»‹ç»ï¼š[ä½¿ç”¨-mineru](https://github.com/opendatalab/MinerU/blob/master/README_zh-CN.md#ä½¿ç”¨-mineru)


## 5. æ³¨æ„äº‹é¡¹

`VastAI`åŠ é€Ÿå¡å¯¹`MinerU`çš„æ”¯æŒæƒ…å†µå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š


<table border="1">
  <thead>
    <tr>
      <th rowspan="2" colspan="2">ä½¿ç”¨åœºæ™¯</th>
      <th>æ”¯æŒæƒ…å†µ</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="5">å‘½ä»¤è¡Œå·¥å…·(mineru)</td>
      <td>pipeline</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>hybrid-http-client</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>hybride-auto-engine</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>vlm-auto-engine</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>vlm-http-client</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td rowspan="5">fastapiæœåŠ¡(mineru-api)</td>
      <td>pipeline</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>hybrid-http-client</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>hybride-auto-engine</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>vlm-auto-engine</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>vlm-http-client</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td rowspan="5">gradioç•Œé¢(mineru-gradio)</td>
      <td>pipeline</td>
      <td>ğŸ”´</td>
    </tr>
    <tr>
      <td>hybrid-http-client</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>hybride-auto-engine</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>vlm-auto-engine</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td>vlm-http-client</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td colspan="2">openai-serveræœåŠ¡ï¼ˆmineru-openai-serverï¼‰</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td colspan="2">Tensorå¹¶è¡Œ (--tensor-parallel-size/--tp)</td>
      <td>ğŸŸ¢</td>
    </tr>
    <tr>
      <td colspan="2">æ•°æ®å¹¶è¡Œ (--data-parallel-size/--dp)</td>
      <td>ğŸ”´</td>
    </tr>
  </tbody>
</table>


> [!NOTE]
> - ğŸŸ¢: æ”¯æŒï¼Œè¿è¡Œè¾ƒç¨³å®šï¼Œç²¾åº¦ä¸NVIDIA GPUåŸºæœ¬ä¸€è‡´  
> - ğŸŸ¡: æ”¯æŒä½†è¾ƒä¸ç¨³å®šï¼Œåœ¨æŸäº›åœºæ™¯ä¸‹å¯èƒ½å‡ºç°å¼‚å¸¸ï¼Œæˆ–ç²¾åº¦å­˜åœ¨ä¸€å®šå·®å¼‚  
> - ğŸ”´: ä¸æ”¯æŒï¼Œæ— æ³•è¿è¡Œï¼Œæˆ–ç²¾åº¦å­˜åœ¨è¾ƒå¤§å·®å¼‚
> - `*-auto-engine`æ¨¡å¼ï¼šVastAIä»…æ”¯æŒvLLMåç«¯
